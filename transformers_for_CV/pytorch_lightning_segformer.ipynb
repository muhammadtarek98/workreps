{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AdamW\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "from PIL import Image\n",
    "from transformers import SegformerForSemanticSegmentation, SegformerImageProcessor ,SegformerFeatureExtractor\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import albumentations as aug\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageSegmentationDataset(Dataset):\n",
    "    \"\"\"Image segmentation dataset.\"\"\"\n",
    "    def __init__(self, root_dir, feature_extractor, transforms=None, train=True):\n",
    "        super(ImageSegmentationDataset,self).__init__()\n",
    "        self.root_dir = root_dir\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.train = train\n",
    "        self.transforms = transforms\n",
    "        self.img_dir = os.path.join(self.root_dir, \"images\")\n",
    "        self.ann_dir = os.path.join(self.root_dir, \"pngmasks\")\n",
    "        image_file_names = []\n",
    "        for root, dirs, files in os.walk(self.img_dir):\n",
    "            image_file_names.extend(files)\n",
    "        self.images = sorted(image_file_names)\n",
    "        \n",
    "        # read annotations\n",
    "        annotation_file_names = []\n",
    "        for root, dirs, files in os.walk(self.ann_dir):\n",
    "            annotation_file_names.extend(files)\n",
    "        self.annotations = sorted(annotation_file_names)\n",
    "\n",
    "        assert len(self.images) == len(self.annotations), \"There must be as many images as there are segmentation maps\"\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image = cv2.imread(os.path.join(self.img_dir, self.images[idx]))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        segmentation_map = cv2.imread(os.path.join(self.ann_dir, self.annotations[idx]))\n",
    "        segmentation_map = cv2.cvtColor(segmentation_map, cv2.COLOR_BGR2GRAY)\n",
    "        if self.transforms is not None:\n",
    "            augmented = self.transforms(image=image, mask=segmentation_map)\n",
    "            encoded_inputs = self.feature_extractor(augmented['image'], augmented['mask'], return_tensors=\"pt\")\n",
    "        else:\n",
    "            encoded_inputs = self.feature_extractor(image, segmentation_map, return_tensors=\"pt\")\n",
    "\n",
    "        for k,v in encoded_inputs.items():\n",
    "            encoded_inputs[k].squeeze_()\n",
    "\n",
    "        return encoded_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = aug.Compose([\n",
    "    aug.Flip(p=0.5)\n",
    "],is_check_shapes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir =r\"D:\\graval detection project\\datasets\\under_water_masks_dataset\\train\"\n",
    "valid_dir=r\"D:\\graval detection project\\datasets\\under_water_masks_dataset\\val\"\n",
    "test_dir=r\"D:\\graval detection project\\datasets\\under_water_masks_dataset\\test\"\n",
    "feature_extractor = SegformerImageProcessor.from_pretrained (\"nvidia/mit-b0\")\n",
    "train_dataset = ImageSegmentationDataset(root_dir=train_dir, feature_extractor=feature_extractor, transforms=transform)\n",
    "valid_dataset = ImageSegmentationDataset(root_dir=valid_dir, feature_extractor=feature_extractor, transforms=None, train=False)\n",
    "test_dataset = ImageSegmentationDataset(root_dir=test_dir, feature_extractor=feature_extractor, transforms=None, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stone']\n",
      "{0: 'stone'}\n",
      "{'stone': 0}\n"
     ]
    }
   ],
   "source": [
    "classes = [\"stone\"]\n",
    "print(classes)\n",
    "id2label = {0:classes[0]}\n",
    "print(id2label)\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True,num_workers=0)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=4,shuffle=False,num_workers=0)\n",
    "test_dataloader  = DataLoader(test_dataset,batch_size=4,shuffle=False,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegformerFinetuner(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, id2label, train_dataloader=None, val_dataloader=None, test_dataloader=None, metrics_interval=100):\n",
    "        super(SegformerFinetuner, self).__init__()\n",
    "        self.id2label = id2label\n",
    "        self.metrics_interval = metrics_interval\n",
    "        self.train_dl = train_dataloader\n",
    "        self.val_dl = val_dataloader\n",
    "        self.test_dl = test_dataloader\n",
    "        self.num_classes = len(id2label.keys())\n",
    "        self.label2id = {v:k for k,v in self.id2label.items()}\n",
    "        self.model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/mit-b0\", ignore_mismatched_sizes=True,\n",
    "                                                         reshape_last_stage=True)\n",
    "        self.train_mean_iou = evaluate.load(\"mean_iou\")\n",
    "        self.val_mean_iou = evaluate.load(\"mean_iou\")\n",
    "        self.test_mean_iou = evaluate.load(\"mean_iou\")\n",
    "        \n",
    "    def forward(self, images, masks):\n",
    "        outputs = self.model(pixel_values=images, labels=masks)\n",
    "        return(outputs)\n",
    "    \n",
    "    def training_step(self, batch, batch_nb):\n",
    "        images, masks = batch['pixel_values'], batch['labels']\n",
    "        outputs = self(images, masks)\n",
    "        loss, logits = outputs[0], outputs[1]\n",
    "        upsampled_logits = nn.functional.interpolate(logits, size=masks.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "        predicted = upsampled_logits.argmax(dim=1)\n",
    "        self.train_mean_iou.add_batch(predictions=predicted.detach().cpu().numpy(), references=masks.detach().cpu().numpy())\n",
    "        if batch_nb % self.metrics_interval == 0:\n",
    "            metrics = self.train_mean_iou.compute(num_labels=self.num_classes, ignore_index=255, reduce_labels=False,)\n",
    "            metrics = {'loss': loss, \"mean_iou\": metrics[\"mean_iou\"], \"mean_accuracy\": metrics[\"mean_accuracy\"]}\n",
    "            for k,v in metrics.items():\n",
    "                self.log(k,v)\n",
    "            return(metrics)\n",
    "        else:\n",
    "            return({'loss': loss})\n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        images, masks = batch['pixel_values'], batch['labels']\n",
    "        outputs = self(images, masks)\n",
    "        loss, logits = outputs[0], outputs[1]\n",
    "        upsampled_logits = nn.functional.interpolate(logits, size=masks.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "        predicted = upsampled_logits.argmax(dim=1)\n",
    "        self.val_mean_iou.add_batch(predictions=predicted.detach().cpu().numpy(), references=masks.detach().cpu().numpy())\n",
    "        return({'val_loss': loss})\n",
    "    \n",
    "    \n",
    "    def test_step(self, batch, batch_nb):\n",
    "        images, masks = batch['pixel_values'], batch['labels']\n",
    "        outputs = self(images, masks)\n",
    "        loss, logits = outputs[0], outputs[1]\n",
    "        upsampled_logits = nn.functional.interpolate(logits, size=masks.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "        predicted = upsampled_logits.argmax(dim=1)\n",
    "        self.test_mean_iou.add_batch(predictions=predicted.detach().cpu().numpy(), references=masks.detach().cpu().numpy())\n",
    "        return({'test_loss': loss})\n",
    "    \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam([p for p in self.parameters() if p.requires_grad], lr=2e-05, eps=1e-08)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return self.train_dl\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return self.val_dl\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return self.test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b0 and are newly initialized: ['decode_head.linear_c.1.proj.weight', 'decode_head.classifier.weight', 'decode_head.classifier.bias', 'decode_head.linear_c.0.proj.weight', 'decode_head.batch_norm.weight', 'decode_head.batch_norm.running_var', 'decode_head.linear_c.2.proj.bias', 'decode_head.linear_c.3.proj.weight', 'decode_head.linear_c.3.proj.bias', 'decode_head.linear_c.0.proj.bias', 'decode_head.linear_c.2.proj.weight', 'decode_head.batch_norm.bias', 'decode_head.linear_fuse.weight', 'decode_head.linear_c.1.proj.bias', 'decode_head.batch_norm.num_batches_tracked', 'decode_head.batch_norm.running_mean']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SegformerFinetuner(\n",
       "  (model): SegformerForSemanticSegmentation(\n",
       "    (segformer): SegformerModel(\n",
       "      (encoder): SegformerEncoder(\n",
       "        (patch_embeddings): ModuleList(\n",
       "          (0): SegformerOverlapPatchEmbeddings(\n",
       "            (proj): Conv2d(3, 32, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "            (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): SegformerOverlapPatchEmbeddings(\n",
       "            (proj): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "            (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): SegformerOverlapPatchEmbeddings(\n",
       "            (proj): Conv2d(64, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "            (layer_norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): SegformerOverlapPatchEmbeddings(\n",
       "            (proj): Conv2d(160, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "            (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (block): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): SegformerLayer(\n",
       "              (layer_norm_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SegformerAttention(\n",
       "                (self): SegformerEfficientSelfAttention(\n",
       "                  (query): Linear(in_features=32, out_features=32, bias=True)\n",
       "                  (key): Linear(in_features=32, out_features=32, bias=True)\n",
       "                  (value): Linear(in_features=32, out_features=32, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  (sr): Conv2d(32, 32, kernel_size=(8, 8), stride=(8, 8))\n",
       "                  (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "                (output): SegformerSelfOutput(\n",
       "                  (dense): Linear(in_features=32, out_features=32, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "              (layer_norm_2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): SegformerMixFFN(\n",
       "                (dense1): Linear(in_features=32, out_features=128, bias=True)\n",
       "                (dwconv): SegformerDWConv(\n",
       "                  (dwconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "                )\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "                (dense2): Linear(in_features=128, out_features=32, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (1): SegformerLayer(\n",
       "              (layer_norm_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SegformerAttention(\n",
       "                (self): SegformerEfficientSelfAttention(\n",
       "                  (query): Linear(in_features=32, out_features=32, bias=True)\n",
       "                  (key): Linear(in_features=32, out_features=32, bias=True)\n",
       "                  (value): Linear(in_features=32, out_features=32, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  (sr): Conv2d(32, 32, kernel_size=(8, 8), stride=(8, 8))\n",
       "                  (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "                (output): SegformerSelfOutput(\n",
       "                  (dense): Linear(in_features=32, out_features=32, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SegformerDropPath(p=0.014285714365541935)\n",
       "              (layer_norm_2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): SegformerMixFFN(\n",
       "                (dense1): Linear(in_features=32, out_features=128, bias=True)\n",
       "                (dwconv): SegformerDWConv(\n",
       "                  (dwconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "                )\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "                (dense2): Linear(in_features=128, out_features=32, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0): SegformerLayer(\n",
       "              (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SegformerAttention(\n",
       "                (self): SegformerEfficientSelfAttention(\n",
       "                  (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "                  (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "                  (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  (sr): Conv2d(64, 64, kernel_size=(4, 4), stride=(4, 4))\n",
       "                  (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "                (output): SegformerSelfOutput(\n",
       "                  (dense): Linear(in_features=64, out_features=64, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SegformerDropPath(p=0.02857142873108387)\n",
       "              (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): SegformerMixFFN(\n",
       "                (dense1): Linear(in_features=64, out_features=256, bias=True)\n",
       "                (dwconv): SegformerDWConv(\n",
       "                  (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "                )\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "                (dense2): Linear(in_features=256, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (1): SegformerLayer(\n",
       "              (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SegformerAttention(\n",
       "                (self): SegformerEfficientSelfAttention(\n",
       "                  (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "                  (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "                  (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  (sr): Conv2d(64, 64, kernel_size=(4, 4), stride=(4, 4))\n",
       "                  (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "                (output): SegformerSelfOutput(\n",
       "                  (dense): Linear(in_features=64, out_features=64, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SegformerDropPath(p=0.04285714402794838)\n",
       "              (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): SegformerMixFFN(\n",
       "                (dense1): Linear(in_features=64, out_features=256, bias=True)\n",
       "                (dwconv): SegformerDWConv(\n",
       "                  (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "                )\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "                (dense2): Linear(in_features=256, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): ModuleList(\n",
       "            (0): SegformerLayer(\n",
       "              (layer_norm_1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SegformerAttention(\n",
       "                (self): SegformerEfficientSelfAttention(\n",
       "                  (query): Linear(in_features=160, out_features=160, bias=True)\n",
       "                  (key): Linear(in_features=160, out_features=160, bias=True)\n",
       "                  (value): Linear(in_features=160, out_features=160, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  (sr): Conv2d(160, 160, kernel_size=(2, 2), stride=(2, 2))\n",
       "                  (layer_norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "                (output): SegformerSelfOutput(\n",
       "                  (dense): Linear(in_features=160, out_features=160, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SegformerDropPath(p=0.05714285746216774)\n",
       "              (layer_norm_2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): SegformerMixFFN(\n",
       "                (dense1): Linear(in_features=160, out_features=640, bias=True)\n",
       "                (dwconv): SegformerDWConv(\n",
       "                  (dwconv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)\n",
       "                )\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "                (dense2): Linear(in_features=640, out_features=160, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (1): SegformerLayer(\n",
       "              (layer_norm_1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SegformerAttention(\n",
       "                (self): SegformerEfficientSelfAttention(\n",
       "                  (query): Linear(in_features=160, out_features=160, bias=True)\n",
       "                  (key): Linear(in_features=160, out_features=160, bias=True)\n",
       "                  (value): Linear(in_features=160, out_features=160, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  (sr): Conv2d(160, 160, kernel_size=(2, 2), stride=(2, 2))\n",
       "                  (layer_norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "                (output): SegformerSelfOutput(\n",
       "                  (dense): Linear(in_features=160, out_features=160, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SegformerDropPath(p=0.0714285746216774)\n",
       "              (layer_norm_2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): SegformerMixFFN(\n",
       "                (dense1): Linear(in_features=160, out_features=640, bias=True)\n",
       "                (dwconv): SegformerDWConv(\n",
       "                  (dwconv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)\n",
       "                )\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "                (dense2): Linear(in_features=640, out_features=160, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): ModuleList(\n",
       "            (0): SegformerLayer(\n",
       "              (layer_norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SegformerAttention(\n",
       "                (self): SegformerEfficientSelfAttention(\n",
       "                  (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): SegformerSelfOutput(\n",
       "                  (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SegformerDropPath(p=0.08571428805589676)\n",
       "              (layer_norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): SegformerMixFFN(\n",
       "                (dense1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                (dwconv): SegformerDWConv(\n",
       "                  (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "                (dense2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (1): SegformerLayer(\n",
       "              (layer_norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SegformerAttention(\n",
       "                (self): SegformerEfficientSelfAttention(\n",
       "                  (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): SegformerSelfOutput(\n",
       "                  (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SegformerDropPath(p=0.10000000149011612)\n",
       "              (layer_norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): SegformerMixFFN(\n",
       "                (dense1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                (dwconv): SegformerDWConv(\n",
       "                  (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                )\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "                (dense2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (layer_norm): ModuleList(\n",
       "          (0): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "          (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decode_head): SegformerDecodeHead(\n",
       "      (linear_c): ModuleList(\n",
       "        (0): SegformerMLP(\n",
       "          (proj): Linear(in_features=32, out_features=256, bias=True)\n",
       "        )\n",
       "        (1): SegformerMLP(\n",
       "          (proj): Linear(in_features=64, out_features=256, bias=True)\n",
       "        )\n",
       "        (2): SegformerMLP(\n",
       "          (proj): Linear(in_features=160, out_features=256, bias=True)\n",
       "        )\n",
       "        (3): SegformerMLP(\n",
       "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (linear_fuse): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (classifier): Conv2d(256, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SegformerFineTuner=SegformerFinetuner(id2label=id2label,train_dataloader=train_dataloader,val_dataloader=valid_dataloader,test_dataloader=test_dataloader,metrics_interval=10)\n",
    "SegformerFineTuner.to(device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=========================================================================================================\n",
       "Layer (type:depth-idx)                                                           Param #\n",
       "=========================================================================================================\n",
       "SegformerFinetuner                                                               --\n",
       "├─SegformerForSemanticSegmentation: 1-1                                          --\n",
       "│    └─SegformerModel: 2-1                                                       --\n",
       "│    │    └─SegformerEncoder: 3-1                                                3,319,392\n",
       "│    └─SegformerDecodeHead: 2-2                                                  --\n",
       "│    │    └─ModuleList: 3-2                                                      132,096\n",
       "│    │    └─Conv2d: 3-3                                                          262,144\n",
       "│    │    └─BatchNorm2d: 3-4                                                     512\n",
       "│    │    └─ReLU: 3-5                                                            --\n",
       "│    │    └─Dropout: 3-6                                                         --\n",
       "│    │    └─Conv2d: 3-7                                                          257,000\n",
       "=========================================================================================================\n",
       "Total params: 3,971,144\n",
       "Trainable params: 3,971,144\n",
       "Non-trainable params: 0\n",
       "========================================================================================================="
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model=SegformerFineTuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "trainer=pl.Trainer(max_epochs=10,val_check_interval=len(valid_dataloader),accelerator=\"gpu\",devices=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                             | Params\n",
      "-----------------------------------------------------------\n",
      "0 | model | SegformerForSemanticSegmentation | 4.0 M \n",
      "-----------------------------------------------------------\n",
      "4.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.0 M     Total params\n",
      "15.885    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9db3658ac7ad4f53af101e12a2d2a6f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f95ca970bd914ce2be304b024a7ac3b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dc5ae09f8944285923de6e130a21960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4a4a274ab847ddb291ab09bc8eb918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a13b17f56df46ffb71200607b5183d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cee34ed0e94a46beb75e861e4324f462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6cf382dab24fbaa1baf6ba34b3dcff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3712f75597634377a7acce5947620142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fccdaac9e2f432ba849381fc76f68b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c55d8e841fc43cf9e8c1929fa50936d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c2ab3358ed74eb4ba8b21091f808df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "668263b9627b4738ab588e8ce7b7b012",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13e0d777b5d445fe8c096229c990bf6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1622a62319bc4057876fd5ca41117e11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model=SegformerFineTuner,train_dataloaders=train_dataloader,val_dataloaders=valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
