{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels_img, features_d):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.features_d = features_d\n",
    "        # VGG16 model\n",
    "        self.vgg16 = torchvision.models.vgg16(weights=torchvision.models.VGG16_Weights.DEFAULT)\n",
    "        for para in self.vgg16.parameters():\n",
    "            para.requires_grad=True\n",
    "        self.vgg16_feature_extractor = nn.Sequential(*list(self.vgg16.features.children())[:])\n",
    "        # Discriminator\n",
    "        self.disc = nn.Sequential(\n",
    "            # input: N x channels_img x 480 x 480 (adjusted for image size 480)\n",
    "            nn.Conv2d(channels_img, features_d, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # _block(in_channels, out_channels, kernel_size, stride, padding)\n",
    "            self._conv_block(features_d, features_d * 2, 4, 2, 1),\n",
    "            self._conv_block(features_d * 2, features_d * 4, 4, 2, 1),\n",
    "            self._conv_block(features_d * 4, features_d * 8, 4, 2, 1),\n",
    "            # After all _block img output is 4x4 (Conv2d below makes into 1x1)\n",
    "            nn.Conv2d(features_d * 8, 1, kernel_size=4, stride=2, padding=0),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    def _conv_block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size,\n",
    "                stride,\n",
    "                padding,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # VGG16 feature extraction\n",
    "        vgg16_features = self.vgg16_feature_extractor(x)\n",
    "        # Discriminator\n",
    "        disc_output = self.disc(x)\n",
    "        return disc_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torchvision.models.vgg16()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "VGG                                      --\n",
       "├─Sequential: 1-1                        --\n",
       "│    └─Conv2d: 2-1                       1,792\n",
       "│    └─ReLU: 2-2                         --\n",
       "│    └─Conv2d: 2-3                       36,928\n",
       "│    └─ReLU: 2-4                         --\n",
       "│    └─MaxPool2d: 2-5                    --\n",
       "│    └─Conv2d: 2-6                       73,856\n",
       "│    └─ReLU: 2-7                         --\n",
       "│    └─Conv2d: 2-8                       147,584\n",
       "│    └─ReLU: 2-9                         --\n",
       "│    └─MaxPool2d: 2-10                   --\n",
       "│    └─Conv2d: 2-11                      295,168\n",
       "│    └─ReLU: 2-12                        --\n",
       "│    └─Conv2d: 2-13                      590,080\n",
       "│    └─ReLU: 2-14                        --\n",
       "│    └─Conv2d: 2-15                      590,080\n",
       "│    └─ReLU: 2-16                        --\n",
       "│    └─MaxPool2d: 2-17                   --\n",
       "│    └─Conv2d: 2-18                      1,180,160\n",
       "│    └─ReLU: 2-19                        --\n",
       "│    └─Conv2d: 2-20                      2,359,808\n",
       "│    └─ReLU: 2-21                        --\n",
       "│    └─Conv2d: 2-22                      2,359,808\n",
       "│    └─ReLU: 2-23                        --\n",
       "│    └─MaxPool2d: 2-24                   --\n",
       "│    └─Conv2d: 2-25                      2,359,808\n",
       "│    └─ReLU: 2-26                        --\n",
       "│    └─Conv2d: 2-27                      2,359,808\n",
       "│    └─ReLU: 2-28                        --\n",
       "│    └─Conv2d: 2-29                      2,359,808\n",
       "│    └─ReLU: 2-30                        --\n",
       "│    └─MaxPool2d: 2-31                   --\n",
       "├─AdaptiveAvgPool2d: 1-2                 --\n",
       "├─Sequential: 1-3                        --\n",
       "│    └─Linear: 2-32                      102,764,544\n",
       "│    └─ReLU: 2-33                        --\n",
       "│    └─Dropout: 2-34                     --\n",
       "│    └─Linear: 2-35                      16,781,312\n",
       "│    └─ReLU: 2-36                        --\n",
       "│    └─Dropout: 2-37                     --\n",
       "│    └─Linear: 2-38                      4,097,000\n",
       "=================================================================\n",
       "Total params: 138,357,544\n",
       "Trainable params: 138,357,544\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis=Discriminator(channels_img=3,features_d=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "Discriminator                            --\n",
       "├─VGG: 1-1                               --\n",
       "│    └─Sequential: 2-1                   --\n",
       "│    │    └─Conv2d: 3-1                  1,792\n",
       "│    │    └─ReLU: 3-2                    --\n",
       "│    │    └─Conv2d: 3-3                  36,928\n",
       "│    │    └─ReLU: 3-4                    --\n",
       "│    │    └─MaxPool2d: 3-5               --\n",
       "│    │    └─Conv2d: 3-6                  73,856\n",
       "│    │    └─ReLU: 3-7                    --\n",
       "│    │    └─Conv2d: 3-8                  147,584\n",
       "│    │    └─ReLU: 3-9                    --\n",
       "│    │    └─MaxPool2d: 3-10              --\n",
       "│    │    └─Conv2d: 3-11                 295,168\n",
       "│    │    └─ReLU: 3-12                   --\n",
       "│    │    └─Conv2d: 3-13                 590,080\n",
       "│    │    └─ReLU: 3-14                   --\n",
       "│    │    └─Conv2d: 3-15                 590,080\n",
       "│    │    └─ReLU: 3-16                   --\n",
       "│    │    └─MaxPool2d: 3-17              --\n",
       "│    │    └─Conv2d: 3-18                 1,180,160\n",
       "│    │    └─ReLU: 3-19                   --\n",
       "│    │    └─Conv2d: 3-20                 2,359,808\n",
       "│    │    └─ReLU: 3-21                   --\n",
       "│    │    └─Conv2d: 3-22                 2,359,808\n",
       "│    │    └─ReLU: 3-23                   --\n",
       "│    │    └─MaxPool2d: 3-24              --\n",
       "│    │    └─Conv2d: 3-25                 2,359,808\n",
       "│    │    └─ReLU: 3-26                   --\n",
       "│    │    └─Conv2d: 3-27                 2,359,808\n",
       "│    │    └─ReLU: 3-28                   --\n",
       "│    │    └─Conv2d: 3-29                 2,359,808\n",
       "│    │    └─ReLU: 3-30                   --\n",
       "│    │    └─MaxPool2d: 3-31              --\n",
       "│    └─AdaptiveAvgPool2d: 2-2            --\n",
       "│    └─Sequential: 2-3                   --\n",
       "│    │    └─Linear: 3-32                 102,764,544\n",
       "│    │    └─ReLU: 3-33                   --\n",
       "│    │    └─Dropout: 3-34                --\n",
       "│    │    └─Linear: 3-35                 16,781,312\n",
       "│    │    └─ReLU: 3-36                   --\n",
       "│    │    └─Dropout: 3-37                --\n",
       "│    │    └─Linear: 3-38                 4,097,000\n",
       "├─Sequential: 1-2                        14,714,688\n",
       "│    └─Conv2d: 2-4                       (recursive)\n",
       "│    └─ReLU: 2-5                         --\n",
       "│    └─Conv2d: 2-6                       (recursive)\n",
       "│    └─ReLU: 2-7                         --\n",
       "│    └─MaxPool2d: 2-8                    --\n",
       "│    └─Conv2d: 2-9                       (recursive)\n",
       "│    └─ReLU: 2-10                        --\n",
       "│    └─Conv2d: 2-11                      (recursive)\n",
       "│    └─ReLU: 2-12                        --\n",
       "│    └─MaxPool2d: 2-13                   --\n",
       "│    └─Conv2d: 2-14                      (recursive)\n",
       "│    └─ReLU: 2-15                        --\n",
       "│    └─Conv2d: 2-16                      (recursive)\n",
       "│    └─ReLU: 2-17                        --\n",
       "│    └─Conv2d: 2-18                      (recursive)\n",
       "│    └─ReLU: 2-19                        --\n",
       "│    └─MaxPool2d: 2-20                   --\n",
       "│    └─Conv2d: 2-21                      (recursive)\n",
       "│    └─ReLU: 2-22                        --\n",
       "│    └─Conv2d: 2-23                      (recursive)\n",
       "│    └─ReLU: 2-24                        --\n",
       "│    └─Conv2d: 2-25                      (recursive)\n",
       "│    └─ReLU: 2-26                        --\n",
       "│    └─MaxPool2d: 2-27                   --\n",
       "│    └─Conv2d: 2-28                      (recursive)\n",
       "│    └─ReLU: 2-29                        --\n",
       "│    └─Conv2d: 2-30                      (recursive)\n",
       "│    └─ReLU: 2-31                        --\n",
       "│    └─Conv2d: 2-32                      (recursive)\n",
       "│    └─ReLU: 2-33                        --\n",
       "│    └─MaxPool2d: 2-34                   --\n",
       "├─Sequential: 1-3                        --\n",
       "│    └─Conv2d: 2-35                      6,272\n",
       "│    └─LeakyReLU: 2-36                   --\n",
       "│    └─Sequential: 2-37                  --\n",
       "│    │    └─Conv2d: 3-39                 524,288\n",
       "│    │    └─LeakyReLU: 3-40              --\n",
       "│    └─Sequential: 2-38                  --\n",
       "│    │    └─Conv2d: 3-41                 2,097,152\n",
       "│    │    └─LeakyReLU: 3-42              --\n",
       "│    └─Sequential: 2-39                  --\n",
       "│    │    └─Conv2d: 3-43                 8,388,608\n",
       "│    │    └─LeakyReLU: 3-44              --\n",
       "│    └─Conv2d: 2-40                      16,385\n",
       "│    └─Sigmoid: 2-41                     --\n",
       "=================================================================\n",
       "Total params: 164,104,937\n",
       "Trainable params: 164,104,937\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model=dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.randn(size=(1,3,480,480))\n",
    "res=dis(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.5038, 0.4998, 0.5008, 0.4971, 0.5012, 0.5031, 0.4981, 0.5016,\n",
      "           0.5024, 0.4940, 0.4990, 0.5007, 0.4960, 0.5003],\n",
      "          [0.4920, 0.5065, 0.4976, 0.5029, 0.4939, 0.4999, 0.4973, 0.4994,\n",
      "           0.4966, 0.5020, 0.4966, 0.4985, 0.5029, 0.5043],\n",
      "          [0.5037, 0.5018, 0.5033, 0.5034, 0.5029, 0.5008, 0.5065, 0.4987,\n",
      "           0.5028, 0.5034, 0.4956, 0.5029, 0.4970, 0.4972],\n",
      "          [0.4993, 0.4993, 0.5034, 0.4956, 0.5003, 0.4960, 0.4993, 0.5013,\n",
      "           0.5024, 0.5007, 0.5026, 0.4997, 0.5055, 0.5001],\n",
      "          [0.5028, 0.5033, 0.4996, 0.5095, 0.5002, 0.4984, 0.5017, 0.4968,\n",
      "           0.4990, 0.5000, 0.4980, 0.5002, 0.5041, 0.5019],\n",
      "          [0.4979, 0.5007, 0.5002, 0.4991, 0.5030, 0.5025, 0.5049, 0.4989,\n",
      "           0.5042, 0.4996, 0.5035, 0.5022, 0.4992, 0.4987],\n",
      "          [0.5045, 0.4939, 0.4998, 0.5016, 0.4984, 0.5052, 0.4965, 0.5002,\n",
      "           0.4987, 0.5038, 0.4969, 0.5030, 0.4959, 0.4989],\n",
      "          [0.5020, 0.5028, 0.4964, 0.5038, 0.5001, 0.4991, 0.5011, 0.4988,\n",
      "           0.4949, 0.4959, 0.5027, 0.5087, 0.4965, 0.5004],\n",
      "          [0.4989, 0.5036, 0.4932, 0.4994, 0.5007, 0.4994, 0.4966, 0.4972,\n",
      "           0.5009, 0.5047, 0.5014, 0.5022, 0.4983, 0.5011],\n",
      "          [0.5013, 0.5003, 0.5066, 0.5012, 0.5033, 0.5033, 0.5017, 0.5008,\n",
      "           0.4981, 0.4970, 0.5018, 0.5001, 0.5021, 0.4995],\n",
      "          [0.5038, 0.5001, 0.5019, 0.5007, 0.5008, 0.4949, 0.5016, 0.5023,\n",
      "           0.5025, 0.5001, 0.5028, 0.4986, 0.5004, 0.4990],\n",
      "          [0.4958, 0.5002, 0.4990, 0.5012, 0.5005, 0.5020, 0.5013, 0.4982,\n",
      "           0.4962, 0.4991, 0.4975, 0.5034, 0.5038, 0.5012],\n",
      "          [0.5042, 0.4972, 0.5038, 0.4965, 0.5019, 0.5036, 0.5022, 0.4974,\n",
      "           0.5017, 0.4957, 0.4942, 0.5005, 0.4982, 0.5005],\n",
      "          [0.5016, 0.4964, 0.4980, 0.4973, 0.5014, 0.5020, 0.4996, 0.4965,\n",
      "           0.4972, 0.5026, 0.5004, 0.4973, 0.5011, 0.5004]]]],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, channels_noise, channels_img, features_g):\n",
    "        super(Generator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            # Input: N x channels_noise x 1 x 1\n",
    "            self._block(channels_noise, features_g * 32, 4, 1, 0),\n",
    "            self._block(features_g * 32, features_g * 16, 4, 1, 0),  # img: 4x4\n",
    "            self._block(features_g * 16, features_g * 8, 4, 2, 1),   # img: 8x8\n",
    "            self._block(features_g * 8, features_g * 4, 4, 2, 1),    # img: 16x16\n",
    "            self._block(features_g * 4, features_g * 2, 4, 2, 1),    # img: 32x32\n",
    "\n",
    "            nn.ConvTranspose2d(\n",
    "                features_g * 2, channels_img, kernel_size=4, stride=2, padding=1\n",
    "            ),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size,\n",
    "                stride,\n",
    "                padding,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, in_channels, H, W = 1, 3, 480, 480\n",
    "noise_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(128, in_channels, 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,images_dir,transform):\n",
    "        super(Dataset,self).__init__()\n",
    "        self.images_dir=images_dir\n",
    "        self.images=os.listdir(self.images_dir)\n",
    "        self.transform=transform\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.images_dir))\n",
    "    def __getitem__(self,idx):\n",
    "        image_dir=self.images[idx]\n",
    "        image=cv2.imread(os.path.join(self.images_dir,image_dir))\n",
    "        image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "        label=torch.tensor(data=[1])\n",
    "        image=self.transform(image)\n",
    "        return image,label\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "LEARNING_RATE_G = 2e-4  # could also use two lrs, one for gen and one for disc\n",
    "LEARNING_RATE_D=1e-2\n",
    "BATCH_SIZE = 1\n",
    "IMAGE_SIZE = 480\n",
    "CHANNELS_IMG = 3\n",
    "NOISE_DIM = 128\n",
    "NUM_EPOCHS = 100\n",
    "FEATURES_DISC = 64\n",
    "FEATURES_GEN = 64\n",
    "\n",
    "transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize(IMAGE_SIZE,antialias=True)\n",
    "    ]\n",
    ")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=Dataset(images_dir=\"GAN_dataset\",transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "image,_=training_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3792, 0.4387, 0.4141,  ..., 0.5222, 0.5079, 0.5902],\n",
      "         [0.3712, 0.4364, 0.4326,  ..., 0.5320, 0.5043, 0.6215],\n",
      "         [0.4543, 0.4513, 0.4479,  ..., 0.6220, 0.5585, 0.6169],\n",
      "         ...,\n",
      "         [0.5989, 0.6022, 0.6065,  ..., 0.5697, 0.5293, 0.5399],\n",
      "         [0.6087, 0.6046, 0.5976,  ..., 0.5703, 0.5364, 0.5465],\n",
      "         [0.5793, 0.5925, 0.6008,  ..., 0.5100, 0.5441, 0.5217]],\n",
      "\n",
      "        [[0.2775, 0.3317, 0.3092,  ..., 0.3305, 0.3292, 0.4293],\n",
      "         [0.2833, 0.3430, 0.3435,  ..., 0.3421, 0.3418, 0.4830],\n",
      "         [0.3845, 0.3930, 0.4101,  ..., 0.4259, 0.4134, 0.5044],\n",
      "         ...,\n",
      "         [0.5353, 0.5300, 0.5318,  ..., 0.5061, 0.4720, 0.4962],\n",
      "         [0.5437, 0.5321, 0.5218,  ..., 0.5129, 0.4760, 0.4937],\n",
      "         [0.5085, 0.5164, 0.5200,  ..., 0.4501, 0.4783, 0.4593]],\n",
      "\n",
      "        [[0.2445, 0.3044, 0.2837,  ..., 0.2612, 0.2465, 0.3430],\n",
      "         [0.2625, 0.3296, 0.3386,  ..., 0.2704, 0.2465, 0.3752],\n",
      "         [0.3656, 0.3787, 0.4045,  ..., 0.3423, 0.2999, 0.3796],\n",
      "         ...,\n",
      "         [0.5078, 0.5051, 0.5085,  ..., 0.4944, 0.4633, 0.4877],\n",
      "         [0.5124, 0.5037, 0.4951,  ..., 0.5248, 0.4772, 0.4895],\n",
      "         [0.4696, 0.4791, 0.4846,  ..., 0.4735, 0.4793, 0.4548]]])\n"
     ]
    }
   ],
   "source": [
    "print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "print(training_data.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen=gen.to(device=device)\n",
    "disc=dis.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_gen = torch.optim.SGD(gen.parameters(), lr=LEARNING_RATE_G)\n",
    "opt_disc = torch.optim.SGD(disc.parameters(), lr=LEARNING_RATE_D)\n",
    "criterion = nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "criterion = nn.BCELoss()\n",
    "fixed_noise = torch.randn(1, NOISE_DIM, 1, 1).to(device)\n",
    "writer_real = SummaryWriter(f\"logs/real\")\n",
    "writer_fake = SummaryWriter(f\"logs/fake\")\n",
    "step = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (vgg16): VGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): ReLU(inplace=True)\n",
       "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (25): ReLU(inplace=True)\n",
       "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (27): ReLU(inplace=True)\n",
       "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (vgg16_feature_extractor): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (disc): Sequential(\n",
       "    (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (5): Conv2d(1024, 1, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (6): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.train()\n",
    "disc.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    # Initializes weights according to the DCGAN paper\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_weights(gen)\n",
    "#initialize_weights(disc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100] Batch 1/56                   Loss D: 0.6930, loss G: 0.6915\n",
      "Epoch [1/100] Batch 1/56                   Loss D: 0.3880, loss G: 0.7249\n",
      "Epoch [2/100] Batch 1/56                   Loss D: 0.0544, loss G: 2.4040\n",
      "Epoch [3/100] Batch 1/56                   Loss D: 0.0172, loss G: 3.7571\n",
      "Epoch [4/100] Batch 1/56                   Loss D: 0.0579, loss G: 2.9082\n"
     ]
    }
   ],
   "source": [
    "# Assuming your generator expects 128 channels\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for batch_idx, (real, _) in enumerate(train_dataloader):\n",
    "        real = real.to(device)\n",
    "        noise = torch.randn(BATCH_SIZE, 128, 1, 1).to(device)  # Use 128 channels for the noise\n",
    "        fake = gen(noise)\n",
    "\n",
    "        ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n",
    "        disc_real = disc(real).reshape(-1)\n",
    "        loss_disc_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "        disc_fake = disc(fake.detach()).reshape(-1)\n",
    "        loss_disc_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "        loss_disc = (loss_disc_real + loss_disc_fake) / 2\n",
    "        disc.zero_grad()\n",
    "        loss_disc.backward()\n",
    "        opt_disc.step()\n",
    "\n",
    "        ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n",
    "        output = disc(fake).reshape(-1)\n",
    "        loss_gen = criterion(output, torch.ones_like(output))\n",
    "        gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        # Print losses occasionally and print to tensorboard\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx+1}/{len(train_dataloader)} \\\n",
    "                  Loss D: {loss_disc:.4f}, loss G: {loss_gen:.4f}\"\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake = gen(fixed_noise)\n",
    "                # take out (up to) 32 examples\n",
    "                img_grid_real = torchvision.utils.make_grid(real[:32], normalize=True)\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake[:32], normalize=True)\n",
    "    \n",
    "                writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n",
    "                writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n",
    "\n",
    "            step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
