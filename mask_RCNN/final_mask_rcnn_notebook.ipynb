{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bM3MhXPd9AY-",
        "outputId": "39721e48-1953-4102-bae4-27517ab18091"
      },
      "outputs": [],
      "source": [
        "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YITHW4rv7mJZ",
        "outputId": "9d52b819-084d-4bf2-f77c-8920a3591d9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:41:10_Pacific_Daylight_Time_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgqBdKPEL31t",
        "outputId": "4295eb02-c79c-4588-bb20-689247685292"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Package                   Version\n",
            "------------------------- ------------\n",
            "alembic                   1.12.1\n",
            "aliyun-python-sdk-core    2.14.0\n",
            "aliyun-python-sdk-kms     2.16.2\n",
            "ansi2html                 1.8.0\n",
            "anyio                     4.1.0\n",
            "argon2-cffi               23.1.0\n",
            "argon2-cffi-bindings      21.2.0\n",
            "arrow                     1.3.0\n",
            "astroid                   3.0.1\n",
            "asttokens                 2.4.0\n",
            "async-lru                 2.0.4\n",
            "attrs                     23.1.0\n",
            "Babel                     2.13.1\n",
            "backcall                  0.2.0\n",
            "beautifulsoup4            4.12.2\n",
            "bleach                    6.1.0\n",
            "blinker                   1.7.0\n",
            "certifi                   2023.7.22\n",
            "cffi                      1.16.0\n",
            "charset-normalizer        3.3.0\n",
            "click                     8.1.7\n",
            "cloudpickle               2.2.1\n",
            "colorama                  0.4.6\n",
            "colored-glog              1.3.0\n",
            "coloredlogs               15.0.1\n",
            "comm                      0.1.4\n",
            "ConfigArgParse            1.7\n",
            "contourpy                 1.1.1\n",
            "crcmod                    1.7\n",
            "cryptography              41.0.5\n",
            "cycler                    0.12.1\n",
            "Cython                    3.0.5\n",
            "dash                      2.13.0\n",
            "dash-core-components      2.0.0\n",
            "dash-html-components      2.0.0\n",
            "dash-table                5.0.0\n",
            "databricks-cli            0.18.0\n",
            "debugpy                   1.8.0\n",
            "decorator                 5.1.1\n",
            "defusedxml                0.7.1\n",
            "dill                      0.3.7\n",
            "docker                    6.1.3\n",
            "dsdl                      0.1.10.11\n",
            "durationpy                0.5\n",
            "entrypoints               0.4\n",
            "environs                  9.5.0\n",
            "exceptiongroup            1.2.0\n",
            "executing                 2.0.0\n",
            "fastjsonschema            2.18.1\n",
            "filelock                  3.12.4\n",
            "Flask                     3.0.0\n",
            "flatbuffers               23.5.26\n",
            "fonttools                 4.43.1\n",
            "fqdn                      1.5.1\n",
            "fsspec                    2023.10.0\n",
            "gdown                     4.7.1\n",
            "gitdb                     4.0.11\n",
            "GitPython                 3.1.40\n",
            "grad-cam                  1.4.8\n",
            "greenlet                  3.0.1\n",
            "huggingface-hub           0.17.3\n",
            "humanfriendly             10.0\n",
            "icecream                  2.1.3\n",
            "idna                      3.4\n",
            "imageio                   2.31.6\n",
            "imgviz                    1.7.4\n",
            "importlib-metadata        6.8.0\n",
            "importlib-resources       6.1.0\n",
            "ipykernel                 6.27.0\n",
            "ipython                   8.12.3\n",
            "ipywidgets                8.1.1\n",
            "isoduration               20.11.0\n",
            "isort                     5.12.0\n",
            "itsdangerous              2.1.2\n",
            "jedi                      0.19.1\n",
            "Jinja2                    3.1.2\n",
            "jmespath                  0.10.0\n",
            "joblib                    1.3.2\n",
            "json5                     0.9.14\n",
            "jsonmodels                2.6.0\n",
            "jsonpointer               2.4\n",
            "jsonschema                4.19.1\n",
            "jsonschema-specifications 2023.7.1\n",
            "jupyter_client            8.6.0\n",
            "jupyter_core              5.3.2\n",
            "jupyter-events            0.9.0\n",
            "jupyter-lsp               2.2.0\n",
            "jupyter_server            2.10.1\n",
            "jupyter_server_terminals  0.4.4\n",
            "jupyterlab                4.0.9\n",
            "jupyterlab_pygments       0.3.0\n",
            "jupyterlab_server         2.25.2\n",
            "jupyterlab-widgets        3.0.9\n",
            "kiwisolver                1.4.5\n",
            "labelme                   5.3.1\n",
            "lazy_loader               0.3\n",
            "Mako                      1.3.0\n",
            "Markdown                  3.5.1\n",
            "markdown-it-py            3.0.0\n",
            "MarkupSafe                2.1.3\n",
            "marshmallow               3.20.1\n",
            "matplotlib                3.7.3\n",
            "matplotlib-inline         0.1.6\n",
            "mccabe                    0.7.0\n",
            "mdurl                     0.1.2\n",
            "mistune                   3.0.2\n",
            "mlflow                    2.8.0\n",
            "mmsegmentation            1.2.1\n",
            "model-index               0.1.11\n",
            "mpmath                    1.3.0\n",
            "natsort                   8.4.0\n",
            "nbclient                  0.7.4\n",
            "nbconvert                 7.11.0\n",
            "nbformat                  5.7.0\n",
            "nest-asyncio              1.5.8\n",
            "networkx                  3.1\n",
            "notebook                  7.0.6\n",
            "notebook_shim             0.2.3\n",
            "numpy                     1.23.5\n",
            "oauthlib                  3.2.2\n",
            "onnxruntime               1.16.3\n",
            "open3d                    0.17.0\n",
            "opencv-contrib-python     4.8.1.78\n",
            "opencv-python             4.8.1.78\n",
            "opendatalab               0.0.10\n",
            "openmim                   0.3.9\n",
            "openxlab                  0.0.28\n",
            "ordered-set               4.1.0\n",
            "oss2                      2.17.0\n",
            "overrides                 7.4.0\n",
            "packaging                 23.2\n",
            "pandas                    2.0.3\n",
            "pandocfilters             1.5.0\n",
            "parso                     0.8.3\n",
            "pef                       1.1.0\n",
            "pickleshare               0.7.5\n",
            "Pillow                    10.0.1\n",
            "pip                       23.3.1\n",
            "pip-review                1.3.0\n",
            "pkgutil_resolve_name      1.3.10\n",
            "platformdirs              3.11.0\n",
            "plotly                    5.17.0\n",
            "pooch                     1.8.0\n",
            "prettytable               3.9.0\n",
            "prometheus-client         0.19.0\n",
            "prompt-toolkit            3.0.39\n",
            "protobuf                  4.25.0\n",
            "psutil                    5.9.5\n",
            "pure-eval                 0.2.2\n",
            "py-cpuinfo                9.0.0\n",
            "pyarrow                   13.0.0\n",
            "pycocotools               2.0.7\n",
            "pycparser                 2.21\n",
            "pycryptodome              3.19.0\n",
            "Pygments                  2.16.1\n",
            "PyJWT                     2.8.0\n",
            "pylint                    3.0.2\n",
            "pyparsing                 3.1.1\n",
            "PyQt5                     5.15.10\n",
            "PyQt5-Qt5                 5.15.2\n",
            "PyQt5-sip                 12.13.0\n",
            "pyreadline3               3.4.1\n",
            "PySide2                   5.15.2.1\n",
            "PySocks                   1.7.1\n",
            "python-dateutil           2.8.2\n",
            "python-dotenv             1.0.0\n",
            "python-json-logger        2.0.7\n",
            "pytz                      2023.3.post1\n",
            "pyvista                   0.42.3\n",
            "PyWavelets                1.4.1\n",
            "pywin32                   306\n",
            "pywinpty                  2.0.12\n",
            "PyYAML                    6.0.1\n",
            "pyzed                     1.3.0\n",
            "pyzmq                     25.1.1\n",
            "QtPy                      2.4.1\n",
            "querystring-parser        1.2.4\n",
            "referencing               0.30.2\n",
            "regex                     2023.10.3\n",
            "requests                  2.31.0\n",
            "retrying                  1.3.4\n",
            "rfc3339-validator         0.1.4\n",
            "rfc3986-validator         0.1.1\n",
            "rich                      13.4.2\n",
            "rpds-py                   0.10.4\n",
            "safetensors               0.4.0\n",
            "scikit-image              0.21.0\n",
            "scikit-learn              1.3.2\n",
            "scipy                     1.10.1\n",
            "scooby                    0.9.2\n",
            "seaborn                   0.13.0\n",
            "Send2Trash                1.8.2\n",
            "setuptools                60.2.0\n",
            "shiboken2                 5.15.2.1\n",
            "six                       1.16.0\n",
            "smmap                     5.0.1\n",
            "sniffio                   1.3.0\n",
            "soupsieve                 2.5\n",
            "SQLAlchemy                2.0.23\n",
            "sqlparse                  0.4.4\n",
            "stack-data                0.6.3\n",
            "sympy                     1.12\n",
            "tabulate                  0.9.0\n",
            "tenacity                  8.2.3\n",
            "termcolor                 2.3.0\n",
            "terminado                 0.18.0\n",
            "terminaltables            3.1.10\n",
            "threadpoolctl             3.2.0\n",
            "tifffile                  2023.7.10\n",
            "timm                      0.9.8\n",
            "tinycss2                  1.2.1\n",
            "tokenizers                0.14.1\n",
            "tomli                     2.0.1\n",
            "tomlkit                   0.12.3\n",
            "torch                     1.8.1+cu101\n",
            "torchaudio                0.8.1\n",
            "torchinfo                 1.8.0\n",
            "torchvision               0.9.1+cu101\n",
            "tornado                   6.3.3\n",
            "tqdm                      4.65.2\n",
            "traitlets                 5.11.2\n",
            "transformers              4.34.1\n",
            "ttach                     0.0.3\n",
            "types-python-dateutil     2.8.19.14\n",
            "typing_extensions         4.8.0\n",
            "tzdata                    2023.3\n",
            "ultralytics               8.0.154\n",
            "uri-template              1.3.0\n",
            "urllib3                   1.26.18\n",
            "vboxapi                   1.0\n",
            "voila                     0.5.5\n",
            "vtk                       9.2.6\n",
            "waitress                  2.1.2\n",
            "wcwidth                   0.2.8\n",
            "webcolors                 1.13\n",
            "webencodings              0.5.1\n",
            "websocket-client          1.6.4\n",
            "websockets                12.0\n",
            "Werkzeug                  3.0.1\n",
            "widgetsnbextension        4.0.9\n",
            "zipp                      3.17.0\n"
          ]
        }
      ],
      "source": [
        "!pip list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jbzNlBJq1l3l"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from shapely.geometry import Polygon\n",
        "from torchvision.io import read_image\n",
        "from torchvision.ops.boxes import masks_to_boxes\n",
        "from torchvision import tv_tensors\n",
        "from torchvision.transforms.v2 import functional as F\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "from detection import utils,transforms,coco_eval,coco_utils\n",
        "from detection.engine import train_one_epoch, evaluate\n",
        "import torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.1.1+cu118'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fYBxFJkoHz5f"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, transforms):\n",
        "        self.root = root\n",
        "        self.transforms = transforms\n",
        "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"images\"))))\n",
        "        self.masks = list(sorted(os.listdir(os.path.join(root, \"masks\"))))\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.root, \"images\", self.imgs[idx])\n",
        "        mask_path = os.path.join(self.root, \"masks\", self.masks[idx])\n",
        "        img = read_image(img_path)\n",
        "        mask = read_image(mask_path)\n",
        "        obj_ids = torch.unique(mask)\n",
        "        obj_ids = obj_ids[1:]\n",
        "        num_objs = len(obj_ids)\n",
        "        masks = (mask == obj_ids[:, None, None]).to(dtype=torch.uint8)\n",
        "        boxes = []\n",
        "        for i in range(num_objs):\n",
        "            pos = np.where(masks[i])\n",
        "            xmin = np.min(pos[1])\n",
        "            xmax = np.max(pos[1])\n",
        "            ymin = np.min(pos[0])\n",
        "            ymax = np.max(pos[0])\n",
        "            if xmin == xmax or ymin == ymax:\n",
        "                continue\n",
        "            boxes.append([xmin, ymin, xmax, ymax])\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
        "        image_id = idx\n",
        "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
        "        img = tv_tensors.Image(img)\n",
        "        target = {}\n",
        "        target[\"boxes\"] = tv_tensors.BoundingBoxes(boxes, format=\"XYXY\", canvas_size=F.get_size(img))\n",
        "        target[\"masks\"] = tv_tensors.Mask(masks)\n",
        "        target[\"labels\"] = labels\n",
        "        target[\"image_id\"] = image_id\n",
        "        target[\"area\"] = area\n",
        "        target[\"iscrowd\"] = iscrowd\n",
        "        if self.transforms is not None:\n",
        "            img, target = self.transforms(img, target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "E4I8SEyePdIB"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import v2 as T\n",
        "def get_transform(train):\n",
        "    transforms = []\n",
        "    if train:\n",
        "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
        "    transforms.append(T.ToDtype(torch.float32, scale=True))\n",
        "    transforms.append(T.ToPureTensor())\n",
        "    return T.Compose(transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "mw_dFS7Odx7x"
      },
      "outputs": [],
      "source": [
        "def get_model_instance_segmentation(num_classes:int):\n",
        "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "    hidden_layer = 256\n",
        "    model.roi_heads.mask_predictor = MaskRCNNPredictor(\n",
        "        in_features_mask,\n",
        "        hidden_layer,\n",
        "        num_classes\n",
        "    )\n",
        "    for parameter in model.parameters():\n",
        "      parameter.requires_grad=True\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "n0MaHsT89M1G"
      },
      "outputs": [],
      "source": [
        "model = get_model_instance_segmentation(num_classes=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_1AY3MgS9sI",
        "outputId": "fd9fb8a7-0374-4f27-c54b-d8480975eaef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "================================================================================\n",
              "Layer (type:depth-idx)                                  Param #\n",
              "================================================================================\n",
              "MaskRCNN                                                --\n",
              "├─GeneralizedRCNNTransform: 1-1                         --\n",
              "├─BackboneWithFPN: 1-2                                  --\n",
              "│    └─IntermediateLayerGetter: 2-1                     --\n",
              "│    │    └─Conv2d: 3-1                                 9,408\n",
              "│    │    └─FrozenBatchNorm2d: 3-2                      --\n",
              "│    │    └─ReLU: 3-3                                   --\n",
              "│    │    └─MaxPool2d: 3-4                              --\n",
              "│    │    └─Sequential: 3-5                             212,992\n",
              "│    │    └─Sequential: 3-6                             1,212,416\n",
              "│    │    └─Sequential: 3-7                             7,077,888\n",
              "│    │    └─Sequential: 3-8                             14,942,208\n",
              "│    └─FeaturePyramidNetwork: 2-2                       --\n",
              "│    │    └─ModuleList: 3-9                             984,064\n",
              "│    │    └─ModuleList: 3-10                            2,360,320\n",
              "│    │    └─LastLevelMaxPool: 3-11                      --\n",
              "├─RegionProposalNetwork: 1-3                            --\n",
              "│    └─AnchorGenerator: 2-3                             --\n",
              "│    └─RPNHead: 2-4                                     --\n",
              "│    │    └─Sequential: 3-12                            590,080\n",
              "│    │    └─Conv2d: 3-13                                771\n",
              "│    │    └─Conv2d: 3-14                                3,084\n",
              "├─RoIHeads: 1-4                                         --\n",
              "│    └─MultiScaleRoIAlign: 2-5                          --\n",
              "│    └─TwoMLPHead: 2-6                                  --\n",
              "│    │    └─Linear: 3-15                                12,846,080\n",
              "│    │    └─Linear: 3-16                                1,049,600\n",
              "│    └─FastRCNNPredictor: 2-7                           --\n",
              "│    │    └─Linear: 3-17                                2,050\n",
              "│    │    └─Linear: 3-18                                8,200\n",
              "│    └─MultiScaleRoIAlign: 2-8                          --\n",
              "│    └─MaskRCNNHeads: 2-9                               --\n",
              "│    │    └─Conv2dNormActivation: 3-19                  590,080\n",
              "│    │    └─Conv2dNormActivation: 3-20                  590,080\n",
              "│    │    └─Conv2dNormActivation: 3-21                  590,080\n",
              "│    │    └─Conv2dNormActivation: 3-22                  590,080\n",
              "│    └─MaskRCNNPredictor: 2-10                          --\n",
              "│    │    └─ConvTranspose2d: 3-23                       262,400\n",
              "│    │    └─ReLU: 3-24                                  --\n",
              "│    │    └─Conv2d: 3-25                                514\n",
              "================================================================================\n",
              "Total params: 43,922,395\n",
              "Trainable params: 43,922,395\n",
              "Non-trainable params: 0\n",
              "================================================================================"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torchinfo.summary(model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 959
        },
        "id": "s2iYk0ATdzhW",
        "outputId": "7a36bca9-afe1-47cf-c5cd-8880e2fedb44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        },
        {
          "ename": "NotImplementedError",
          "evalue": "Could not run 'torchvision::nms' with arguments from the 'CUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'torchvision::nms' is only available for these backends: [CPU, QuantizedCPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMeta, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nCPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\cpu\\nms_kernel.cpp:112 [kernel]\nQuantizedCPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\quantized\\cpu\\qnms_kernel.cpp:124 [kernel]\nBackendSelect: fallthrough registered at ..\\aten\\src\\ATen\\core\\BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ..\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:153 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at ..\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:498 [backend fallback]\nFunctionalize: registered at ..\\aten\\src\\ATen\\FunctionalizeFallbackKernel.cpp:290 [backend fallback]\nNamed: registered at ..\\aten\\src\\ATen\\core\\NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ..\\aten\\src\\ATen\\ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at ..\\aten\\src\\ATen\\native\\NegateFallback.cpp:19 [backend fallback]\nZeroTensor: registered at ..\\aten\\src\\ATen\\ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:86 [backend fallback]\nAutogradOther: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:53 [backend fallback]\nAutogradCPU: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:57 [backend fallback]\nAutogradCUDA: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:65 [backend fallback]\nAutogradXLA: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:69 [backend fallback]\nAutogradMPS: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:77 [backend fallback]\nAutogradXPU: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:61 [backend fallback]\nAutogradHPU: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:90 [backend fallback]\nAutogradLazy: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:73 [backend fallback]\nAutogradMeta: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:81 [backend fallback]\nTracer: registered at ..\\torch\\csrc\\autograd\\TraceTypeManual.cpp:296 [backend fallback]\nAutocastCPU: fallthrough registered at ..\\aten\\src\\ATen\\autocast_mode.cpp:382 [backend fallback]\nAutocastCUDA: fallthrough registered at ..\\aten\\src\\ATen\\autocast_mode.cpp:249 [backend fallback]\nFuncTorchBatched: registered at ..\\aten\\src\\ATen\\functorch\\LegacyBatchingRegistrations.cpp:710 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at ..\\aten\\src\\ATen\\functorch\\VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at ..\\aten\\src\\ATen\\LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at ..\\aten\\src\\ATen\\VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at ..\\aten\\src\\ATen\\functorch\\TensorWrapper.cpp:203 [backend fallback]\nPythonTLSSnapshot: registered at ..\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:161 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at ..\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:494 [backend fallback]\nPreDispatch: registered at ..\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:165 [backend fallback]\nPythonDispatcher: registered at ..\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:157 [backend fallback]\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[14], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> 40\u001b[0m         run\u001b[38;5;241m=\u001b[39m\u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_data_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m         lr_scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     42\u001b[0m         valid\u001b[38;5;241m=\u001b[39mevaluate(model, valid_data_loader, device\u001b[38;5;241m=\u001b[39mdevice)\n",
            "File \u001b[1;32md:\\graval detection project\\mask_RCNN\\detection\\engine.py:31\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, optimizer, data_loader, device, epoch, print_freq, scaler)\u001b[0m\n\u001b[0;32m     29\u001b[0m targets \u001b[38;5;241m=\u001b[39m [{k: v\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m targets]\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(enabled\u001b[38;5;241m=\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 31\u001b[0m     loss_dict \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(loss \u001b[38;5;28;01mfor\u001b[39;00m loss \u001b[38;5;129;01min\u001b[39;00m loss_dict\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# reduce losses over all GPUs for logging purposes\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\torchvision\\models\\detection\\generalized_rcnn.py:104\u001b[0m, in \u001b[0;36mGeneralizedRCNN.forward\u001b[1;34m(self, images, targets)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(features, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    103\u001b[0m     features \u001b[38;5;241m=\u001b[39m OrderedDict([(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m, features)])\n\u001b[1;32m--> 104\u001b[0m proposals, proposal_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrpn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m detections, detector_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroi_heads(features, proposals, images\u001b[38;5;241m.\u001b[39mimage_sizes, targets)\n\u001b[0;32m    106\u001b[0m detections \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform\u001b[38;5;241m.\u001b[39mpostprocess(detections, images\u001b[38;5;241m.\u001b[39mimage_sizes, original_image_sizes)  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\torchvision\\models\\detection\\rpn.py:372\u001b[0m, in \u001b[0;36mRegionProposalNetwork.forward\u001b[1;34m(self, images, features, targets)\u001b[0m\n\u001b[0;32m    370\u001b[0m proposals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbox_coder\u001b[38;5;241m.\u001b[39mdecode(pred_bbox_deltas\u001b[38;5;241m.\u001b[39mdetach(), anchors)\n\u001b[0;32m    371\u001b[0m proposals \u001b[38;5;241m=\u001b[39m proposals\u001b[38;5;241m.\u001b[39mview(num_images, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m--> 372\u001b[0m boxes, scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter_proposals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproposals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjectness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_anchors_per_level\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    374\u001b[0m losses \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n",
            "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\torchvision\\models\\detection\\rpn.py:288\u001b[0m, in \u001b[0;36mRegionProposalNetwork.filter_proposals\u001b[1;34m(self, proposals, objectness, image_shapes, num_anchors_per_level)\u001b[0m\n\u001b[0;32m    285\u001b[0m boxes, scores, lvl \u001b[38;5;241m=\u001b[39m boxes[keep], scores[keep], lvl[keep]\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# non-maximum suppression, independently done per level\u001b[39;00m\n\u001b[1;32m--> 288\u001b[0m keep \u001b[38;5;241m=\u001b[39m \u001b[43mbox_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatched_nms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnms_thresh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;66;03m# keep only topk scoring predictions\u001b[39;00m\n\u001b[0;32m    291\u001b[0m keep \u001b[38;5;241m=\u001b[39m keep[: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_nms_top_n()]\n",
            "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\torchvision\\ops\\boxes.py:73\u001b[0m, in \u001b[0;36mbatched_nms\u001b[1;34m(boxes, scores, idxs, iou_threshold)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# Benchmarks that drove the following thresholds are at\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# https://github.com/pytorch/vision/issues/1311#issuecomment-781329339\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m boxes\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m (\u001b[38;5;241m4000\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m boxes\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m20000\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torchvision\u001b[38;5;241m.\u001b[39m_is_tracing():\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_batched_nms_vanilla\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miou_threshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _batched_nms_coordinate_trick(boxes, scores, idxs, iou_threshold)\n",
            "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\torch\\jit\\_trace.py:1230\u001b[0m, in \u001b[0;36m_script_if_tracing.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1226\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1228\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tracing():\n\u001b[0;32m   1229\u001b[0m         \u001b[38;5;66;03m# Not tracing, don't do anything\u001b[39;00m\n\u001b[1;32m-> 1230\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1232\u001b[0m     compiled_fn \u001b[38;5;241m=\u001b[39m script(wrapper\u001b[38;5;241m.\u001b[39m__original_fn)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   1233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m compiled_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\torchvision\\ops\\boxes.py:109\u001b[0m, in \u001b[0;36m_batched_nms_vanilla\u001b[1;34m(boxes, scores, idxs, iou_threshold)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m class_id \u001b[38;5;129;01min\u001b[39;00m torch\u001b[38;5;241m.\u001b[39munique(idxs):\n\u001b[0;32m    108\u001b[0m     curr_indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(idxs \u001b[38;5;241m==\u001b[39m class_id)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 109\u001b[0m     curr_keep_indices \u001b[38;5;241m=\u001b[39m \u001b[43mnms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboxes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcurr_indices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcurr_indices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miou_threshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m     keep_mask[curr_indices[curr_keep_indices]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    111\u001b[0m keep_indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(keep_mask)[\u001b[38;5;241m0\u001b[39m]\n",
            "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\torchvision\\ops\\boxes.py:41\u001b[0m, in \u001b[0;36mnms\u001b[1;34m(boxes, scores, iou_threshold)\u001b[0m\n\u001b[0;32m     39\u001b[0m     _log_api_usage_once(nms)\n\u001b[0;32m     40\u001b[0m _assert_has_ops()\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miou_threshold\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\torch\\_ops.py:692\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    688\u001b[0m     \u001b[38;5;66;03m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[0;32m    689\u001b[0m     \u001b[38;5;66;03m# is still callable from JIT\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     \u001b[38;5;66;03m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[0;32m    691\u001b[0m     \u001b[38;5;66;03m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[1;32m--> 692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs \u001b[38;5;129;01mor\u001b[39;00m {})\n",
            "\u001b[1;31mNotImplementedError\u001b[0m: Could not run 'torchvision::nms' with arguments from the 'CUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'torchvision::nms' is only available for these backends: [CPU, QuantizedCPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMeta, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nCPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\cpu\\nms_kernel.cpp:112 [kernel]\nQuantizedCPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\quantized\\cpu\\qnms_kernel.cpp:124 [kernel]\nBackendSelect: fallthrough registered at ..\\aten\\src\\ATen\\core\\BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ..\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:153 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at ..\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:498 [backend fallback]\nFunctionalize: registered at ..\\aten\\src\\ATen\\FunctionalizeFallbackKernel.cpp:290 [backend fallback]\nNamed: registered at ..\\aten\\src\\ATen\\core\\NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ..\\aten\\src\\ATen\\ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at ..\\aten\\src\\ATen\\native\\NegateFallback.cpp:19 [backend fallback]\nZeroTensor: registered at ..\\aten\\src\\ATen\\ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:86 [backend fallback]\nAutogradOther: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:53 [backend fallback]\nAutogradCPU: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:57 [backend fallback]\nAutogradCUDA: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:65 [backend fallback]\nAutogradXLA: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:69 [backend fallback]\nAutogradMPS: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:77 [backend fallback]\nAutogradXPU: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:61 [backend fallback]\nAutogradHPU: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:90 [backend fallback]\nAutogradLazy: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:73 [backend fallback]\nAutogradMeta: registered at ..\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:81 [backend fallback]\nTracer: registered at ..\\torch\\csrc\\autograd\\TraceTypeManual.cpp:296 [backend fallback]\nAutocastCPU: fallthrough registered at ..\\aten\\src\\ATen\\autocast_mode.cpp:382 [backend fallback]\nAutocastCUDA: fallthrough registered at ..\\aten\\src\\ATen\\autocast_mode.cpp:249 [backend fallback]\nFuncTorchBatched: registered at ..\\aten\\src\\ATen\\functorch\\LegacyBatchingRegistrations.cpp:710 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at ..\\aten\\src\\ATen\\functorch\\VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at ..\\aten\\src\\ATen\\LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at ..\\aten\\src\\ATen\\VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at ..\\aten\\src\\ATen\\functorch\\TensorWrapper.cpp:203 [backend fallback]\nPythonTLSSnapshot: registered at ..\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:161 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at ..\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:494 [backend fallback]\nPreDispatch: registered at ..\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:165 [backend fallback]\nPythonDispatcher: registered at ..\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:157 [backend fallback]\n"
          ]
        }
      ],
      "source": [
        "train_dir = r\"D:\\graval detection project\\datasets\\under_water_masks_dataset\\train\"\n",
        "valid_dir=r\"D:\\graval detection project\\datasets\\under_water_masks_dataset\\val\"\n",
        "test_dir=r\"D:\\graval detection project\\datasets\\under_water_masks_dataset\\test\"\n",
        "train_transforms = get_transform(train=True)\n",
        "vaild_transforms=get_transform(train=False)\n",
        "test_transforms=get_transform(train=False)\n",
        "\n",
        "\n",
        "training_dataset = CustomDataset(\n",
        "        root=train_dir,\n",
        "        transforms=train_transforms)\n",
        "valid_dataset=CustomDataset(\n",
        "        root=valid_dir,\n",
        "        transforms=vaild_transforms)\n",
        "test_dataset=CustomDataset(root=test_dir,transforms=test_transforms)\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.Adam(params, lr=1e-4, betas=(0.9,0.99), weight_decay=0.0005)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
        "                                                   step_size=5,\n",
        "                                                   gamma=0.1)\n",
        "training_data_loader = torch.utils.data.DataLoader(\n",
        "    training_dataset,\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    collate_fn=utils.collate_fn\n",
        ")\n",
        "valid_data_loader=torch.utils.data.DataLoader(\n",
        "    valid_dataset,\n",
        "    batch_size=2,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    collate_fn=utils.collate_fn\n",
        ")\n",
        "num_epochs = 10\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "model.to(device)\n",
        "for epoch in range(num_epochs):\n",
        "        run=train_one_epoch(model, optimizer, training_data_loader, device, epoch, print_freq=100)\n",
        "        lr_scheduler.step()\n",
        "        valid=evaluate(model, valid_data_loader, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dS1WFkQR9kj"
      },
      "outputs": [],
      "source": [
        "%matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import draw_bounding_boxes, draw_segmentation_masks\n",
        "test=r\"D:\\graval detection project\\datasets\\unperpared data\\images under water\\images\\40_left_2023_10_22_10_44_36.jpg\"\n",
        "image = read_image(test)\n",
        "eval_transform = get_transform(train=False)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    x = eval_transform(image)\n",
        "    x = x[:3, ...].to(device)\n",
        "    predictions = model([x, ])\n",
        "    pred = predictions[0]\n",
        "image = (255.0 * (image - image.min()) / (image.max() - image.min())).to(torch.uint8)\n",
        "image = image[:3, ...]\n",
        "pred_labels = [f\"stone: {score:.3f}\" for label, score in zip(pred[\"labels\"], pred[\"scores\"])]\n",
        "pred_boxes = pred[\"boxes\"]\n",
        "output_image = draw_bounding_boxes(image, pred_boxes, pred_labels, colors=\"red\")\n",
        "masks = (pred[\"masks\"] >=0.1).squeeze(1)\n",
        "output_image = draw_segmentation_masks(output_image, masks, alpha=0.2, colors=\"green\")\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.imshow(output_image.permute(1, 2, 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iksAP4sZU9A6"
      },
      "outputs": [],
      "source": [
        "print(pred[\"boxes\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyyse0_9TeQs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
